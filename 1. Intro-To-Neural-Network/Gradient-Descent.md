## Gradient Descent

<img width="634" alt="Screen Shot 2019-09-24 at 9 23 52 AM" src="https://user-images.githubusercontent.com/46575719/65515302-0a98b800-dead-11e9-8e12-8023f3d3ad98.png">
 
 Now we learned that in order to minimize the error function, we need to take some derivatives. 
 So let's get our hands dirty and actually compute the derivative of the error function. 
 The first thing to notice is that the sigmoid function has a really nice derivative.

<img width="798" alt="Screen Shot 2019-09-24 at 9 25 35 AM" src="https://user-images.githubusercontent.com/46575719/65515577-86930000-dead-11e9-9841-68e2a82323a6.png">

<img width="791" alt="Screen Shot 2019-09-24 at 9 27 03 AM" src="https://user-images.githubusercontent.com/46575719/65515581-86930000-dead-11e9-97ac-934a0cb09813.png">

<img width="800" alt="Screen Shot 2019-09-24 at 9 26 23 AM" src="https://user-images.githubusercontent.com/46575719/65515580-86930000-dead-11e9-8101-e039a9c83a6f.png">

<img width="802" alt="Screen Shot 2019-09-24 at 9 26 43 AM" src="https://user-images.githubusercontent.com/46575719/65515579-86930000-dead-11e9-90c0-8b6d0ce2cbaf.png">


